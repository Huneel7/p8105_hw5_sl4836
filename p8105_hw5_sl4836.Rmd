---
title: "p8105_hw5_sl4836"
author: "Hun"
date: "11/13/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(purrr)
library(janitor)
library(readr)

```

```{r}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem_0 - Creating Local Data File
```{r}
dir.create(file.path(getwd(), "hw5_data_file"), recursive = TRUE)

list.files()
```


### Problem 1
```{r}
urlfile = "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"

homicide_data <- read_csv(url(urlfile))
```


```{r}
homicide_nrow <- nrow(homicide_data)
homicide_ncol <- ncol(homicide_data)
homicide_variables <- names(homicide_data)

```

The dimension of the homicide_data is **`r homicide_nrow` x**  **`r homicide_ncol`.** There are **`r homicide_nrow`** number of observations of homicide cases in the 50 large U.S. cities and **`r homicide_ncol`**  variables: *`r homicide_variables`.*



```{r}
homicide_clean_data <-
  homicide_data %>%
  mutate(city_state = str_c(city, state),
         resolution = case_when(
          disposition == "Closed without arrest" ~ "unsolved",
         disposition == "Open/No arrest" ~ "unsolved",
         disposition == "Closed by arrest" ~ "solved"
         ))  %>%
  relocate(city_state) %>%
  filter(city_state != "TulsaAL")


```


```{r}
baltimore_df <-  
  homicide_clean_data %>%
  filter(city_state == "BaltimoreMD")

baltimore_summary <-
  baltimore_df %>% 
  summarise(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )

baltimore_test <-
  prop.test(
  x = baltimore_summary %>% pull(unsolved),
  n = baltimore_summary %>% pull(n)
  )

baltimore_test %>% 
  broom::tidy()
```
```{r}
prop_test_fucntion <- function(city_df) {
  
  city_summary =
  city_df %>% 
  summarise(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )
  
  city_test =
  prop.test(
  x = city_summary %>% pull(unsolved),
  n = city_summary %>% pull(n)
  )
  
  
  return(city_test)
}


```


```{r}
nested_df <-
  homicide_clean_data %>% 
  nest(data = uid:resolution) %>%
  mutate(
    test_results = map(data, prop_test_fucntion),
    tidy_results = map(test_results, broom::tidy)
  ) %>%
  select(city_state, tidy_results) %>%
  unnest(tidy_results) %>%
  select(city_state, estimate, starts_with("conf"))
```

```{r}
nested_df
```



```{r}
nested_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


### Problem 2 - Importing Data
```{r}
data_files <- 
  tibble(list.files("./hw5_data_file")) %>%
  mutate(file_list = paste(list.files("./hw5_data_file")))

```

### Problem 2 - Creating functions to read multiple datasets in the list
```{r, message = FALSE}
read_files <- function(x) {
  
    data = read_csv(paste0("./hw5_data_file/", x)) %>%
      mutate(file_names = x)
}

arm_dataset <- map_df(data_files$file_list, read_files)

arm_dataset
```

### Problem 2 - Tidying and wrangling the dataset
```{r}
clean_arm_dataset <-
  arm_dataset %>%
  janitor::clean_names() %>%
  gather(key = week, value = arm_value, week_1:week_8) %>%
  mutate(week = str_remove(week, "week_")) %>%
  mutate(subject_ID = as.integer(str_extract(file_names, "[0-9][0-9]"))) %>%
  mutate(file_names = ifelse(str_detect(file_names, "con") == TRUE,
                             "Control", "Experiment")) %>%
  mutate(across(.cols = c(file_names, week, subject_ID), as.factor)) %>%
  relocate(file_names, subject_ID, arm_value)

clean_arm_dataset
```


### Problem 2 - Making a spaghetti plot showing observations on each subject over time
```{r}
clean_arm_dataset %>%
  ggplot(aes(week, arm_value, color=subject_ID)) + 
  geom_point(size = 0.2) + 
  geom_line(aes(group = subject_ID), alpha=0.5) +
  facet_grid(~file_names) +
  labs(x = "Week", y = "Arm Value", 
       title = "Arm Values on Each Subject over 8 Weeks in Two Groups",
       col = "Subject ID") +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
  
```

In the experiment group, the arm values of subjects by and large show an upward trend over time during 8 weeks though the time for and magnitude of changes are different within subjects. On the other hand, in the control group, the arm values of subjects in overall fluctuate over time without any certain trends or patterns and by and large there is no huge changes in arm values within subjects compared to subjects in the experiment group. Another interesting observation is none of the subjects in the control group reach arm value beyond 5 whereas about half the subjects in the experiment group reach arm value beyond 5 over time. 

### Problem 3 - Importing data with missing vlaues
```{r}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

### Problem 3 - creating a function to fill in missing vlaues

```{r}
fill_na <- function(v) {
  
  if (is.numeric(v)) {
    v = replace_na(v, mean(v, na.rm = T))
  }
  else if(is.character(v)) {
    v = replace_na(v, "virginica")
  }
  return(as.vector(v))
}

result <- 
  map(.x = iris_with_missing, ~fill_na(.x))

result

map(.x = result, ~is.vector(.x))
```

```{r}
result_as_data_frame <- 
  map_df(.x = iris_with_missing, ~fill_na(.x))

result_as_data_frame
```




